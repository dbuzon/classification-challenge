{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Débora Buzon da Silva 10851687"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução\n",
    "\n",
    "Neste projeto estremos analisando e explorando dados do seguinte *dataset* [Hotel Resevations Dataset](https://www.kaggle.com/datasets/ahsan81/hotel-reservations-classification-dataset?resource=download), com o objetivo de responder à questão: **Será que um hóspede irá cancelar sua reserva?**\n",
    "\n",
    "Prever se um hóspede irá cancelar sua reserva ou não é de grande importância para os hotéis, pois podem gerar prejuízo. Além disso, a capacidade de prever tais cancelamentos com precisão permite que os hotéis tomem medidas preventivas para evitá-los.\n",
    "\n",
    "Ao longo desse projeto, iremos implementar métodos para responder à questão proposta usando técnicas básicas como KNN (*K Nearest Neighbours*) e *Naive-Bayes*, e técnicas mais avançadas como *Extra Trees*.\n",
    "\n",
    "O projeto atualizado pode ser acessado no [Github](https://github.com/dbuzon/classification-challenge).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise Exploratória dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Booking_ID</th>\n",
       "      <th>no_of_adults</th>\n",
       "      <th>no_of_children</th>\n",
       "      <th>no_of_weekend_nights</th>\n",
       "      <th>no_of_week_nights</th>\n",
       "      <th>type_of_meal_plan</th>\n",
       "      <th>required_car_parking_space</th>\n",
       "      <th>room_type_reserved</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_year</th>\n",
       "      <th>arrival_month</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>market_segment_type</th>\n",
       "      <th>repeated_guest</th>\n",
       "      <th>no_of_previous_cancellations</th>\n",
       "      <th>no_of_previous_bookings_not_canceled</th>\n",
       "      <th>avg_price_per_room</th>\n",
       "      <th>no_of_special_requests</th>\n",
       "      <th>booking_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INN00001</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Meal Plan 1</td>\n",
       "      <td>0</td>\n",
       "      <td>Room_Type 1</td>\n",
       "      <td>224</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Offline</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.00</td>\n",
       "      <td>0</td>\n",
       "      <td>Not_Canceled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INN00002</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Not Selected</td>\n",
       "      <td>0</td>\n",
       "      <td>Room_Type 1</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>Online</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106.68</td>\n",
       "      <td>1</td>\n",
       "      <td>Not_Canceled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INN00003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Meal Plan 1</td>\n",
       "      <td>0</td>\n",
       "      <td>Room_Type 1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>Online</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0</td>\n",
       "      <td>Canceled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INN00004</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Meal Plan 1</td>\n",
       "      <td>0</td>\n",
       "      <td>Room_Type 1</td>\n",
       "      <td>211</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>Online</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0</td>\n",
       "      <td>Canceled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INN00005</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Selected</td>\n",
       "      <td>0</td>\n",
       "      <td>Room_Type 1</td>\n",
       "      <td>48</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>Online</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Canceled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Booking_ID  no_of_adults  no_of_children  no_of_weekend_nights   \n",
       "0   INN00001             2               0                     1  \\\n",
       "1   INN00002             2               0                     2   \n",
       "2   INN00003             1               0                     2   \n",
       "3   INN00004             2               0                     0   \n",
       "4   INN00005             2               0                     1   \n",
       "\n",
       "   no_of_week_nights type_of_meal_plan  required_car_parking_space   \n",
       "0                  2       Meal Plan 1                           0  \\\n",
       "1                  3      Not Selected                           0   \n",
       "2                  1       Meal Plan 1                           0   \n",
       "3                  2       Meal Plan 1                           0   \n",
       "4                  1      Not Selected                           0   \n",
       "\n",
       "  room_type_reserved  lead_time  arrival_year  arrival_month  arrival_date   \n",
       "0        Room_Type 1        224          2017             10             2  \\\n",
       "1        Room_Type 1          5          2018             11             6   \n",
       "2        Room_Type 1          1          2018              2            28   \n",
       "3        Room_Type 1        211          2018              5            20   \n",
       "4        Room_Type 1         48          2018              4            11   \n",
       "\n",
       "  market_segment_type  repeated_guest  no_of_previous_cancellations   \n",
       "0             Offline               0                             0  \\\n",
       "1              Online               0                             0   \n",
       "2              Online               0                             0   \n",
       "3              Online               0                             0   \n",
       "4              Online               0                             0   \n",
       "\n",
       "   no_of_previous_bookings_not_canceled  avg_price_per_room   \n",
       "0                                     0               65.00  \\\n",
       "1                                     0              106.68   \n",
       "2                                     0               60.00   \n",
       "3                                     0              100.00   \n",
       "4                                     0               94.50   \n",
       "\n",
       "   no_of_special_requests booking_status  \n",
       "0                       0   Not_Canceled  \n",
       "1                       1   Not_Canceled  \n",
       "2                       0       Canceled  \n",
       "3                       0       Canceled  \n",
       "4                       0       Canceled  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lendo dataframe\n",
    "df = pd.read_csv('./hotel_reservations.csv')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O conjunto possui os seguintes dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36275 entries, 0 to 36274\n",
      "Data columns (total 19 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   Booking_ID                            36275 non-null  object \n",
      " 1   no_of_adults                          36275 non-null  int64  \n",
      " 2   no_of_children                        36275 non-null  int64  \n",
      " 3   no_of_weekend_nights                  36275 non-null  int64  \n",
      " 4   no_of_week_nights                     36275 non-null  int64  \n",
      " 5   type_of_meal_plan                     36275 non-null  object \n",
      " 6   required_car_parking_space            36275 non-null  int64  \n",
      " 7   room_type_reserved                    36275 non-null  object \n",
      " 8   lead_time                             36275 non-null  int64  \n",
      " 9   arrival_year                          36275 non-null  int64  \n",
      " 10  arrival_month                         36275 non-null  int64  \n",
      " 11  arrival_date                          36275 non-null  int64  \n",
      " 12  market_segment_type                   36275 non-null  object \n",
      " 13  repeated_guest                        36275 non-null  int64  \n",
      " 14  no_of_previous_cancellations          36275 non-null  int64  \n",
      " 15  no_of_previous_bookings_not_canceled  36275 non-null  int64  \n",
      " 16  avg_price_per_room                    36275 non-null  float64\n",
      " 17  no_of_special_requests                36275 non-null  int64  \n",
      " 18  booking_status                        36275 non-null  object \n",
      "dtypes: float64(1), int64(13), object(5)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento\n",
    "\n",
    "Foi feito um mapeamento dos dados não numéricos como *meal_plan*, e *booking_status* para valores correspondentes em números, utilizando a biblioteca LabelEncoder do sklearn.processing. Como por exemplo, no *booking_status* 1 significa que a reserva não foi cancelada e 0 o contrário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Booking_ID</th>\n",
       "      <th>no_of_adults</th>\n",
       "      <th>no_of_children</th>\n",
       "      <th>no_of_weekend_nights</th>\n",
       "      <th>no_of_week_nights</th>\n",
       "      <th>type_of_meal_plan</th>\n",
       "      <th>required_car_parking_space</th>\n",
       "      <th>room_type_reserved</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_year</th>\n",
       "      <th>arrival_month</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>market_segment_type</th>\n",
       "      <th>repeated_guest</th>\n",
       "      <th>no_of_previous_cancellations</th>\n",
       "      <th>no_of_previous_bookings_not_canceled</th>\n",
       "      <th>avg_price_per_room</th>\n",
       "      <th>no_of_special_requests</th>\n",
       "      <th>booking_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INN00001</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>224</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INN00002</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106.68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INN00003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INN00004</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INN00005</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Booking_ID  no_of_adults  no_of_children  no_of_weekend_nights   \n",
       "0   INN00001             2               0                     1  \\\n",
       "1   INN00002             2               0                     2   \n",
       "2   INN00003             1               0                     2   \n",
       "3   INN00004             2               0                     0   \n",
       "4   INN00005             2               0                     1   \n",
       "\n",
       "   no_of_week_nights  type_of_meal_plan  required_car_parking_space   \n",
       "0                  2                  0                           0  \\\n",
       "1                  3                  3                           0   \n",
       "2                  1                  0                           0   \n",
       "3                  2                  0                           0   \n",
       "4                  1                  3                           0   \n",
       "\n",
       "   room_type_reserved  lead_time  arrival_year  arrival_month  arrival_date   \n",
       "0                   0        224          2017             10             2  \\\n",
       "1                   0          5          2018             11             6   \n",
       "2                   0          1          2018              2            28   \n",
       "3                   0        211          2018              5            20   \n",
       "4                   0         48          2018              4            11   \n",
       "\n",
       "   market_segment_type  repeated_guest  no_of_previous_cancellations   \n",
       "0                    3               0                             0  \\\n",
       "1                    4               0                             0   \n",
       "2                    4               0                             0   \n",
       "3                    4               0                             0   \n",
       "4                    4               0                             0   \n",
       "\n",
       "   no_of_previous_bookings_not_canceled  avg_price_per_room   \n",
       "0                                     0               65.00  \\\n",
       "1                                     0              106.68   \n",
       "2                                     0               60.00   \n",
       "3                                     0              100.00   \n",
       "4                                     0               94.50   \n",
       "\n",
       "   no_of_special_requests  booking_status  \n",
       "0                       0               1  \n",
       "1                       1               1  \n",
       "2                       0               0  \n",
       "3                       0               0  \n",
       "4                       0               0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tratamento dos dados\n",
    "label_encoder_type_of_meal_plan = LabelEncoder()\n",
    "label_encoder_room_type_reserved = LabelEncoder()\n",
    "label_encoder_market_segment_type = LabelEncoder()\n",
    "label_encoder_booking_status = LabelEncoder()\n",
    "\n",
    "df['type_of_meal_plan'] = label_encoder_type_of_meal_plan.fit_transform(df['type_of_meal_plan'])\n",
    "df['room_type_reserved'] = label_encoder_room_type_reserved.fit_transform(df['room_type_reserved'])\n",
    "df['market_segment_type'] = label_encoder_market_segment_type.fit_transform(df['market_segment_type'])\n",
    "df['booking_status'] = label_encoder_booking_status.fit_transform(df['booking_status'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, o conjunto é desbalanceado. O número de instâncias de reservas não canceladas é mais do que o dobro do que o de canceladas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "booking_status\n",
       "Not_Canceled    24390\n",
       "Canceled        11885\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['booking_status'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos dados que iremos utilizar para predizer Y, iremos remover a coluna *booking_status* (nosso target) e o *Booking_ID*, pois ele não é relevante nas predições. Para tratar o desbalanceamento está sendo utilizada a biblioteca *RandomOverSampler* a qual gera dados fictícios baseados no *dataset* original, de forma a igualar as proporções do valor de *booking_status*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Booking_ID', 'booking_status'], axis=1)\n",
    "Y = df['booking_status']\n",
    "\n",
    "# geração de novos dados para balancear a proporção de reservas canceladas e não canceladas\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X, Y = ros.fit_resample(X, Y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Técnicas Utilizadas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por meio de testes foi determinado que um número maior de folds proporcianava um aumento na acurácia de todos os métodos, alguns com aumentos mais significativos que outros. Por isso estamos utilizando 30 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definição do cross-validation\n",
    "kFolds = 30\n",
    "kf = StratifiedKFold(n_splits=kFolds, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia com 1 K-NN: 0.8997 +/- 0.0071\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "score_knn = cross_val_score(knn, X, Y, cv=kf, n_jobs=-1)\n",
    "print('Acurácia com 1 K-NN: %0.4f +/- %0.4f' % (score_knn.mean(), score_knn.std()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive-Bayes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O *Naive-Bayes* teve uma acurácia bem baixa utilizando todas as colunas do dataframe, pois nem todos são contínuos. Vemos que quando selecionamos melhor as colunas temos um aumento significativo na acurácia de mais de 10%, porém o KNN continua sendo um método mais adequado para os dados em questão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia com Naive-Bayes e todas as colunas: 0.5671 +/- 0.0067\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "scores = cross_val_score(nb, X, Y, cv=kf)\n",
    "print('Acurácia com Naive-Bayes e todas as colunas: %0.4f +/- %0.4f' % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia com Naive-Bayes e valores contínuos: 0.6814 +/- 0.0096\n"
     ]
    }
   ],
   "source": [
    "Xnb = df[['lead_time', 'avg_price_per_room']]\n",
    "Ynb = df['booking_status']\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "Xnb, Ynb = ros.fit_resample(Xnb, Ynb)\n",
    "score_nb = cross_val_score(nb, Xnb, Ynb, cv=kf)\n",
    "print('Acurácia com Naive-Bayes e valores contínuos: %0.4f +/- %0.4f' % (score_nb.mean(), score_nb.std()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão Logística"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar ao *Naive-Bayes*, a Regressão Logística também não tem uma performance tão boa quanto ao KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia com Regressão Logística: 0.7789 +/- 0.0093\n"
     ]
    }
   ],
   "source": [
    "rlog = LogisticRegression(max_iter=5000)\n",
    "score_rlog = cross_val_score(rlog, X, Y, cv=kf, n_jobs=-1)\n",
    "print('Acurácia com Regressão Logística: %0.4f +/- %0.4f' % (score_rlog.mean(), score_rlog.std()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='linear')\n",
    "scores = cross_val_score(svm, X, Y, cv=kf)\n",
    "print('Acurácia com SVM Linear: %0.4f +/- %0.4f' % (scores.mean(), scores.std()))\n",
    "\n",
    "svm = SVC(kernel='rbf')\n",
    "scores = cross_val_score(svm, X, Y, cv=kf)\n",
    "print('Acurácia com SVM RBF: %0.4f +/- %0.4f' % (scores.mean(), scores.std()))\n",
    "\n",
    "svm = SVC(kernel='poly', degree=3)\n",
    "scores = cross_val_score(svm, X, Y, cv=kf)\n",
    "print('Acurácia com SVM Poly: %0.4f +/- %0.4f' % (scores.mean(), scores.std()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árvores de Decisão"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que o melhor algoritmo para as árvores de decisão é o *entropy*, sendo também o método com maior acurácia até agora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia com Gini: 0.9292 +/- 0.0052\n",
      "Acurácia com Entropy: 0.9313 +/- 0.0067\n"
     ]
    }
   ],
   "source": [
    "#classificação\n",
    "dct = tree.DecisionTreeClassifier()\n",
    "score_dct_gini = cross_val_score(dct, X, Y, cv=kf)\n",
    "print('Acurácia com Gini: %0.4f +/- %0.4f' % (score_dct_gini.mean(), score_dct_gini.std())) \n",
    "\n",
    "dct = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "score_dct_entropy = cross_val_score(dct, X, Y, cv=kf)\n",
    "print('Acurácia com Entropy: %0.4f +/- %0.4f' % (score_dct_entropy.mean(), score_dct_entropy.std())) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/derb/.local/lib/python3.8/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/home/derb/.local/lib/python3.8/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/home/derb/.local/lib/python3.8/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/home/derb/.local/lib/python3.8/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Pasting é um Bagging sem reposição de exemplos (bootstrap=False)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m bag \u001b[39m=\u001b[39m BaggingClassifier(base_estimator\u001b[39m=\u001b[39mSVC(), n_estimators\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, bootstrap\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m scores \u001b[39m=\u001b[39m cross_val_score(bag, X, Y, cv\u001b[39m=\u001b[39;49mkf, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mAcurácia Pasting com SVC: \u001b[39m\u001b[39m%0.4f\u001b[39;00m\u001b[39m +/- \u001b[39m\u001b[39m%0.4f\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (scores\u001b[39m.\u001b[39mmean(), scores\u001b[39m.\u001b[39mstd()))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[1;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    527\u001b[0m )\n\u001b[1;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m    269\u001b[0m         X,\n\u001b[1;32m    270\u001b[0m         y,\n\u001b[1;32m    271\u001b[0m         scorers,\n\u001b[1;32m    272\u001b[0m         train,\n\u001b[1;32m    273\u001b[0m         test,\n\u001b[1;32m    274\u001b[0m         verbose,\n\u001b[1;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    276\u001b[0m         fit_params,\n\u001b[1;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    437\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 439\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    441\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    442\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    303\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bag = BaggingClassifier(estimator=SVC(), n_estimators=10)\n",
    "scores = cross_val_score(bag, X, Y, cv=kf, n_jobs=-1)\n",
    "print('Acurácia Bagging com SVC: %0.4f +/- %0.4f' % (scores.mean(), scores.std())) \n",
    "\n",
    "# Pasting é um Bagging sem reposição de exemplos (bootstrap=False)\n",
    "bag = BaggingClassifier(estimator=SVC(), n_estimators=10, bootstrap=False)\n",
    "scores = cross_val_score(bag, X, Y, cv=kf, n_jobs=-1)\n",
    "print('Acurácia Pasting com SVC: %0.4f +/- %0.4f' % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia Random Forest Gini: 0.9492 +/- 0.0055\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "score_rf = cross_val_score(rf, X, Y, cv=kf, n_jobs=-1)\n",
    "print('Acurácia Random Forest Gini: %0.4f +/- %0.4f' % (score_rf.mean(), score_rf.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia Ada Boost: 0.8026 +/- 0.0086\n"
     ]
    }
   ],
   "source": [
    "bag = AdaBoostClassifier(n_estimators=50)\n",
    "score_ada = cross_val_score(bag, X, Y, cv=kf, n_jobs=-1)\n",
    "print('Acurácia Ada Boost: %0.4f +/- %0.4f' % (score_ada.mean(), score_ada.std())) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees\n",
    "\n",
    "*Extra Trees* é um algoritmo de aprendizado de máquina que utiliza várias árvores de decisão para fazer previsões sobre dados. Ele é chamado de \"Extra\" porque, ao contrário de outros algoritmos de árvore de decisão, ele utiliza mais aleatoriedade para criar cada árvore, o que aumenta a robustez do modelo.\n",
    "\n",
    "O *Extra Trees* é bem similar ao *Random Forest*,aA principal diferença entre eles é que o *Extra Trees* utiliza mais aleatoriedade ao treinar cada árvore, enquanto o *Random Forest* utiliza uma técnica adicional de amostragem de recursos para reduzir a correlação entre as árvores e aumentar a robustez do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia Extra Trees Gini: 0.9487 +/- 0.0056\n"
     ]
    }
   ],
   "source": [
    "extra_trees = ExtraTreesClassifier()\n",
    "score_ext = cross_val_score(extra_trees, X, Y, cv=kf, n_jobs=-1)\n",
    "print('Acurácia Extra Trees Gini: %0.4f +/- %0.4f' % (score_ext.mean(), score_ext.std())) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise dos Resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>Decision Tree Gini</th>\n",
       "      <th>Decision Tree Entropy</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Extra Trees</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>AdaBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>KNN</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>AdaBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scaling</th>\n",
       "      <td>Normal Data</td>\n",
       "      <td>Normal Data</td>\n",
       "      <td>Normal Data</td>\n",
       "      <td>Normal Data</td>\n",
       "      <td>Normal Data</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>StandardScaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>Gaussian</td>\n",
       "      <td>Gini</td>\n",
       "      <td>Gini</td>\n",
       "      <td>Gini</td>\n",
       "      <td>Gini</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.681406</td>\n",
       "      <td>0.929172</td>\n",
       "      <td>0.931304</td>\n",
       "      <td>0.949221</td>\n",
       "      <td>0.948708</td>\n",
       "      <td>0.899733</td>\n",
       "      <td>0.778905</td>\n",
       "      <td>0.802563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Naive Bayes Decision Tree Gini Decision Tree Entropy   \n",
       "Model      Naive Bayes      Decision Tree         Decision Tree  \\\n",
       "Scaling    Normal Data        Normal Data           Normal Data   \n",
       "Type          Gaussian               Gini                  Gini   \n",
       "Precision     0.681406           0.929172              0.931304   \n",
       "\n",
       "           Random Forest  Extra Trees       KNN  Logistic Regression   \n",
       "Model      Random Forest  Extra Trees       KNN  Logistic Regression  \\\n",
       "Scaling      Normal Data  Normal Data    Normal               Normal   \n",
       "Type                Gini         Gini         -                    -   \n",
       "Precision       0.949221     0.948708  0.899733             0.778905   \n",
       "\n",
       "                 AdaBoost  \n",
       "Model            AdaBoost  \n",
       "Scaling    StandardScaler  \n",
       "Type                    -  \n",
       "Precision        0.802563  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NaiveBayes = {'Model':'Naive Bayes',\n",
    "               'Scaling':'Normal Data',\n",
    "               'Type':'Gaussian',\n",
    "               'Precision':score_nb.mean()}\n",
    "\n",
    "DCTGini = {'Model':'Decision Tree',\n",
    "               'Scaling':'Normal Data',\n",
    "               'Type': 'Gini',\n",
    "               'Precision':score_dct_gini.mean()}\n",
    "\n",
    "DCTEntropy = {'Model':'Decision Tree',\n",
    "               'Scaling':'Normal Data',\n",
    "               'Type': 'Gini',\n",
    "               'Precision':score_dct_entropy.mean()}\n",
    "\n",
    "Random = {'Model':'Random Forest',\n",
    "               'Scaling':'Normal Data',\n",
    "               'Type': 'Gini',\n",
    "               'Precision':score_rf.mean()}\n",
    "\n",
    "Extra = {'Model':'Extra Trees',\n",
    "               'Scaling':'Normal Data',\n",
    "               'Type': 'Gini',\n",
    "               'Precision':score_ext.mean()}\n",
    "\n",
    "KNN = {'Model':'KNN',\n",
    "               'Scaling':'Normal',\n",
    "               'Type':'-',\n",
    "               'Precision':score_knn.mean()}\n",
    "\n",
    "Logistic = {'Model':'Logistic Regression',\n",
    "               'Scaling':'Normal',\n",
    "               'Type':'-',\n",
    "               'Precision':score_rlog.mean()}\n",
    "\n",
    "AdaBoosting = {'Model':'AdaBoost',\n",
    "               'Scaling':'StandardScaler',\n",
    "               'Type':'-',\n",
    "               'Precision':score_ada.mean()}\n",
    "\n",
    "resume = pd.DataFrame({'Naive Bayes':pd.Series(NaiveBayes),\n",
    "                       'Decision Tree Gini':pd.Series(DCTGini),\n",
    "                       'Decision Tree Entropy':pd.Series(DCTEntropy),\n",
    "                       'Random Forest':pd.Series(Random),\n",
    "                       'Extra Trees':pd.Series(Extra),                       \n",
    "                       'KNN':pd.Series(KNN),\n",
    "                       'Logistic Regression':pd.Series(Logistic),\n",
    "                       'AdaBoost':pd.Series(AdaBoosting),\n",
    "                      })\n",
    "resume\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusão\n",
    "\n",
    "Vimos que os melhores modelos para o conjunto de dados utilizado foram Árvores de Decisão com o algoritmo *entropy*, *Random Forest* com seus parâmetros padrão e o *Extra Trees*, que é muito similar ao *Random Forest*. Além disso, ao analisar a correlação dos dados, foi possível verificar que o tempo de antecedência (*lead_time*) com que a pessoa faz a reserva e o preço do quarto (*avg_price_per_room*) foram as variáveis mais importantes para a previsão. Isso sugere que as políticas de precificação e gestão de reservas podem ter um impacto significativo na redução de cancelamentos, e, portanto, essas informações podem ser usadas para desenvolver estratégias de negócios mais eficazes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apêndice\n",
    "\n",
    "## Detecção de água envenenada\n",
    "Este artigo apresenta uma proposta de detecção de água envenenada através do uso de sinais Wi-Fi e técnicas de machine learning. Quatro classificadores foram utilizados: SVM, k-nearest neighbor, LSTM e Adaboost, sendo avaliados por meio de cross-validation com 5 folds e métricas como AUC, TPR, TNR, F1-Score e Accuracy. Todos os algoritmos apresentaram resultados satisfatórios, com destaque para o KNN com precisão de 82% e Adaboost com 92% na diferenciação entre água envenenada nos níveis de 100 ppm e 1000 ppm.\n",
    "\n",
    "## Predição da Recidiva de Câncer\n",
    "O artigo \"Um Estudo sobre a Predição da Recidiva de Câncer Usando Técnicas de Aprendizado de Máquina\", tinha como objetivo identificar a recidiva de câncer em dados binários, ou seja, identificando se houve ou não tratamento para a doença. Um aspecto interessante deste estudo foi o tratamento dado ao desbalanceamento dos dados, utilizando o SMOTE para aumentar a classe minoritária.\n",
    "\n",
    "## CatBoost\n",
    "CatBoost é um gradient boosting que se destaca por lidar de forma mais eficaz com características categóricas em comparação a outras implementações de boosting disponíveis. Desenvolvido pela Yandex, ele introduziu avanços algorítmicos, como o boosting encomendado e um algoritmo inovador para processamento de características categóricas, a fim de combater a mudança de predição causada pelo vazamento de alvo presente em algoritmos de reforço de gradiente existentes. Com desempenho superior em diversos conjuntos de dados, o CatBoost tem se mostrado uma opção promissora para aprimorar a eficácia de algoritmos de machine learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
